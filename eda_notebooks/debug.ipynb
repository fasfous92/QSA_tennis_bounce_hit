{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6aa910fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.signal import savgol_filter\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.signal import find_peaks\n",
    "import os \n",
    "import dotenv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "#load dotenv\n",
    "dotenv.load_dotenv()\n",
    "DATA_FOLDER=os.environ.get(\"DATA_FOLDER\")\n",
    "\n",
    "\n",
    "def cosine_similarity_rows(df, window_size=4, threshold=1e-5):\n",
    "    '''\n",
    "    This function would compute the consine similarity between the velocity vectore before and after ou\n",
    "    point. This could help us detect a sudden or a big angle change depicting hence a potential\n",
    "    hit or bounce.      \n",
    "    '''\n",
    "    vx_before = df['x_smooth'] - df['x_smooth'].shift(window_size).bfill()\n",
    "    vy_before = df['y_smooth'] - df['y_smooth'].shift(window_size).bfill()\n",
    "   \n",
    "    vx_after = df['x_smooth'].shift(-window_size).ffill() - df['x_smooth']\n",
    "    vy_after = df['y_smooth'].shift(-window_size).ffill() - df['y_smooth']\n",
    "    \n",
    "    A = np.array([vx_before, vy_before], dtype=np.float32).T\n",
    "    B = np.array([vx_after, vy_after], dtype=np.float32).T \n",
    "    \n",
    "    #Dot product\n",
    "    dot_products = np.sum(A * B, axis=1)\n",
    "    \n",
    "    #compute of norm\n",
    "    norm_A = np.linalg.norm(A, axis=1)\n",
    "    norm_B = np.linalg.norm(B, axis=1)\n",
    "    \n",
    "   # to avoid diviing by zero\n",
    "    valid_mask = (norm_A > threshold) & (norm_B > threshold)\n",
    "    \n",
    "    similarities = np.ones(len(df), dtype=np.float32)\n",
    "    \n",
    "    \n",
    "    similarities[valid_mask] = dot_products[valid_mask] / (norm_A[valid_mask] * norm_B[valid_mask])\n",
    "    \n",
    "    # Use the same function to compute the velocity magnitude change\n",
    "    delta_speed = norm_B - norm_A \n",
    "    \n",
    "    #return np.clip(similarities, -1.0, 1.0), delta_speed\n",
    "    return similarities, delta_speed\n",
    "\n",
    "\n",
    "def get_window_slope(data, window_size):\n",
    "    \"\"\"\n",
    "    Calculates the slope of a moving window efficiently.\n",
    "    opposite slopes specialy in y might indicate a hit\n",
    "    \"\"\"\n",
    "    windows = sliding_window_view(data, window_size)\n",
    "    \n",
    "    #compute the delta t to compute the slope\n",
    "    x = np.arange(window_size)\n",
    "    \n",
    "    N = window_size\n",
    "    sum_x = np.sum(x)\n",
    "    sum_x_sq = np.sum(x**2)\n",
    "    delta = N * sum_x_sq - sum_x**2\n",
    "    \n",
    "    sum_y = np.sum(windows, axis=1)\n",
    "    sum_xy = np.sum(windows * x, axis=1)\n",
    "    \n",
    "    slopes = (N * sum_xy - sum_x * sum_y) / delta\n",
    "    \n",
    "    return slopes\n",
    "\n",
    "def windowed_acceleration(df, window_size=5):\n",
    "    \n",
    "    vx_data = df['x_smooth'].values.astype(float)\n",
    "    vy_data = df['y_smooth'].values.astype(float)\n",
    "    \n",
    "    # get the slope which is the velcity (windowed)\n",
    "    vx_trend = get_window_slope(vx_data, window_size)\n",
    "    vy_trend = get_window_slope(vy_data, window_size)\n",
    "    \n",
    "    # differentiate to get the acceleration\n",
    "    ax = np.diff(vx_trend)\n",
    "    ay = np.diff(vy_trend)\n",
    "    \n",
    "    # Pad the result to match original length\n",
    "    # The sliding window reduces length by (window_size - 1)\n",
    "    # The diff reduces length by 1\n",
    "    # Total lost = window_size\n",
    "    \n",
    "    pad_start = window_size // 2\n",
    "    pad_end = max(0, len(df) - len(ax) - pad_start)\n",
    "    \n",
    "    ax = np.pad(ax, (pad_start, pad_end), constant_values=0)\n",
    "    ay = np.pad(ay, (pad_start, pad_end), constant_values=0)\n",
    "    \n",
    "    return ax, ay\n",
    "\n",
    "\n",
    "def fit_piecewise_linear(df, breakpoints):\n",
    "    \"\"\"\n",
    "    The main idea behind this is to reconstruct our smooth and parabolic \n",
    "    time series and make it fit in picewise linear function. This might help \n",
    "    us making hits and  bounces more relevent and hence increase their selctability.\n",
    "    breakpoints are points where we observe certain peaks hence we use them as boundaries \n",
    "    for our piecewise linear reconstruction.\n",
    "    \"\"\"\n",
    "   \n",
    "    boundaries = sorted(list(set([0, len(df)] + list(breakpoints))))\n",
    "    \n",
    "    # Prepare an array to hold the linear reconstruction \n",
    "    linear_fit = np.full(len(df), np.nan)\n",
    "    \n",
    "    # List to store the equation of each line: (slope, intercept)\n",
    "    line_equations = []\n",
    "\n",
    "    # 2. Iterate through each segment\n",
    "    for i in range(len(boundaries) - 1):\n",
    "        start, end = int(boundaries[i]), int(boundaries[i+1])\n",
    "        \n",
    "        X_segment = np.arange(start, end).reshape(-1, 1) \n",
    "        y_segment = df['y'].iloc[start:end].values\n",
    "        \n",
    "        if len(y_segment) < 2:\n",
    "            continue\n",
    "            \n",
    "        # fit Linear Model\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_segment, y_segment)\n",
    "        \n",
    "        y_pred = model.predict(X_segment)\n",
    "        \n",
    "        linear_fit[start:end] = y_pred\n",
    "        \n",
    "        line_equations.append({\n",
    "            'segment': (start, end),\n",
    "            'slope': model.coef_[0],      \n",
    "            'intercept': model.intercept_\n",
    "        })\n",
    "        \n",
    "    return linear_fit, line_equations\n",
    "\n",
    "\n",
    "def merge_close_points(points, threshold=10):\n",
    "    \"\"\"\n",
    "    Groups detected peak points that are within 'threshold' frames of each other \n",
    "    and returns the average frame index for each group. The main observation was that \n",
    "    certain slopes were considered as peaks hence we tried to merge them.\n",
    "    \n",
    "    \"\"\"\n",
    "    if len(points) == 0:\n",
    "        return np.array([], dtype=int)\n",
    "    \n",
    "    sorted_pts = np.sort(points)\n",
    "    \n",
    "    merged_points = []\n",
    "    current_cluster = [sorted_pts[0]]\n",
    "    \n",
    "    for i in range(1, len(sorted_pts)):\n",
    "        # if this point is close to the last one in the cluster, add it\n",
    "        if sorted_pts[i] - current_cluster[-1] < threshold:\n",
    "            current_cluster.append(sorted_pts[i])\n",
    "        else:\n",
    "            # Cluster finished: calculate mean and save\n",
    "            mean_frame = np.mean(current_cluster)\n",
    "            merged_points.append(mean_frame)\n",
    "            # Start new cluster\n",
    "            current_cluster = [sorted_pts[i]]\n",
    "            \n",
    "    # last cluster\n",
    "    if current_cluster:\n",
    "        merged_points.append(np.mean(current_cluster))\n",
    "        \n",
    "    return np.array(merged_points, dtype=int)\n",
    "\n",
    "\n",
    "def calculate_peak_distances(total_frames, peak_indices):\n",
    "    \"\"\"\n",
    "    For every point we calculate the distance to the closest peak.\n",
    "    If the distance 0 this might be a peak, but also close points are harder to determine \n",
    "    but this also helps us detect air points (very far from peaks).\n",
    "    \"\"\"\n",
    "    if len(peak_indices) == 0:\n",
    "        return np.zeros(total_frames)\n",
    "    \n",
    "    all_frames = np.arange(total_frames)\n",
    "    \n",
    "    # We subtract every point from every peak, finding the absolute min\n",
    "    distances = np.abs(all_frames[:, None] - peak_indices[None, :])\n",
    "    \n",
    "    # Get the minimum value along the rows (closest peak for each frame)\n",
    "    min_distances = np.min(distances, axis=1)\n",
    "    \n",
    "    return min_distances\n",
    "\n",
    "\n",
    "def Kinematics(df, x_col='x', y_col='y', fps=30, smooth_window=3):\n",
    "    \"\"\"\n",
    "    Detects most of the kinematics variables:\n",
    "    -velocity on x and y\n",
    "    -acceleration on x and y\n",
    "    -jerk on x and y\n",
    "    -turning angle\n",
    "\n",
    "    \"\"\"\n",
    "    # 1. PREPROCESSING: Smooth the data to reduce tracking noise\n",
    "    # We use a rolling mean, but Savitzky-Golay is better for production\n",
    "    #df = df.copy()\n",
    "    # df[f'{x_col}_smooth'] = df[x_col].rolling(window=smooth_window, center=True).mean().fillna(df[x_col])\n",
    "    # df[f'{y_col}_smooth'] = df[y_col].rolling(window=smooth_window, center=True).mean().fillna(df[y_col])\n",
    "\n",
    "    # Time delta (dt)\n",
    "    dt = 1 / fps\n",
    "\n",
    "    # 2. KINEMATICS: Calculate Velocity and Acceleration\n",
    "    # Velocity (First Derivative)\n",
    "    df['vx'] = np.gradient(df[f'{x_col}_smooth'], dt)\n",
    "    df['vy'] = np.gradient(df[f'{y_col}_smooth'], dt)\n",
    "    df['speed'] = np.sqrt(df['vx']**2 + df['vy']**2)\n",
    "\n",
    "    # Acceleration (Second Derivative)\n",
    "    df['ax'] = np.gradient(df['vx'], dt)\n",
    "    df['ay'] = np.gradient(df['vy'], dt)\n",
    "    df['acc_mag'] = np.sqrt(df['ax']**2 + df['ay']**2)\n",
    "\n",
    "    # Jerk (Third Derivative - The \"Shock\" detector)\n",
    "    # High jerk indicates a sudden physical event (collision)\n",
    "    df['jerk_mag'] = np.gradient(df['acc_mag'], dt)\n",
    "\n",
    "    # 3. CURVATURE: Calculate Turning Angle (0 to 180 degrees)\n",
    "    # A generic \"straight\" flight has angle ~0. A hit has angle > 0.\n",
    "    # We use dot product of normalized velocity vectors\n",
    "    vx_norm = df['vx'] / (df['speed'] + 1e-6) # Avoid div/0\n",
    "    vy_norm = df['vy'] / (df['speed'] + 1e-6)\n",
    "    \n",
    "    # Calculate dot product between vector t and t-1\n",
    "    # We shift the normalized vectors by 1 frame to compare t vs t-1\n",
    "    dot_product = (vx_norm * vx_norm.shift(1)) + (vy_norm * vy_norm.shift(1))\n",
    "    # Clip to valid range for arccos [-1, 1]\n",
    "    dot_product = dot_product.clip(-1.0, 1.0)\n",
    "    df['turn_angle_deg'] = np.degrees(np.arccos(dot_product)).fillna(0)\n",
    "  \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def preprocess(df):\n",
    "    #create a smooth version for better fixing of censors sensibility\n",
    "    df['x_smooth'] = savgol_filter(df['x'], window_length=7, polyorder=2)\n",
    "    df['y_smooth'] = savgol_filter(df['y'], window_length=7, polyorder=2)\n",
    "    \n",
    "    df=Kinematics(df, fps=30)\n",
    "    #cosine similarity between velcoity before/after and also difference of speed \n",
    "    df['cosine_sim'],df['speed_delta'] = cosine_similarity_rows(df, 4)\n",
    "\n",
    "    # #get the acceleration \n",
    "    # ax, ay = windowed_acceleration(df, window_size=10)\n",
    "\n",
    "    # # Total magnitude of windowed acceleration\n",
    "    # acc_magnitude = np.sqrt(ax**2 + ay**2)\n",
    "\n",
    "    # df['acc_x'] = ax\n",
    "    # df['acc_y'] = ay\n",
    "    # df['acc_mag'] = acc_magnitude\n",
    "\n",
    "    \n",
    "    #detect pick points using scipy module\n",
    "    y_data = df['y_smooth'].values\n",
    "    peaks, _ = find_peaks(y_data, prominence=20, distance=5)\n",
    "    valleys, _ = find_peaks(-y_data, prominence=20, distance=5)\n",
    "    raw_points = np.concatenate([peaks, valleys])\n",
    "\n",
    "    # Merge Close Peak points to avoid miss interpretations\n",
    "    final_events = merge_close_points(raw_points, threshold=15)\n",
    "\n",
    "    # --- CRITICAL FIX: MAP TO DATAFRAME INDEX ---\n",
    "    # We use these 0-based positions to grab the REAL frame numbers from df.index\n",
    "    actual_event_frames = df.index[final_events]\n",
    "    old_event_frames=df.index[raw_points]\n",
    "    # 3. Calculate Distances\n",
    "    # We pass the 0-based 'final_events' because 'calculate_peak_distances' \n",
    "    # generates a 0-based range internally.\n",
    "    dist_array = calculate_peak_distances(len(df), final_events)\n",
    "    df['dist_to_event'] = dist_array  # Assigning to DF automatically aligns it to DF index\n",
    "\n",
    "    to_drop=['x', 'y','x_smooth', 'y_smooth']\n",
    "    df=df.drop(columns=to_drop)\n",
    "    \n",
    "    return   df\n",
    "\n",
    "\n",
    "def preprocessing_per_file(df,num=3):\n",
    "    df=df[df['visible']==True].copy()\n",
    "    preprocess_df=preprocess(df)\n",
    "  \n",
    "    #df.drop(columns=['visible'])\n",
    "    \n",
    "    eps = 1e-15\n",
    "    for i in range(1, num):\n",
    "        df['x_lag_{}'.format(i)] = df['x'].shift(i)\n",
    "        df['x_lag_inv_{}'.format(i)] = df['x'].shift(-i)\n",
    "        df['y_lag_{}'.format(i)] = df['y'].shift(i)\n",
    "        df['y_lag_inv_{}'.format(i)] = df['y'].shift(-i) \n",
    "        df['x_diff_{}'.format(i)] = abs(df['x_lag_{}'.format(i)] - df['x'])\n",
    "        df['y_diff_{}'.format(i)] = df['y_lag_{}'.format(i)] - df['y']\n",
    "        df['x_diff_inv_{}'.format(i)] = abs(df['x_lag_inv_{}'.format(i)] - df['x'])\n",
    "        df['y_diff_inv_{}'.format(i)] = df['y_lag_inv_{}'.format(i)] - df['y']\n",
    "        df['x_div_{}'.format(i)] = abs(df['x_diff_{}'.format(i)]/(df['x_diff_inv_{}'.format(i)] + eps))\n",
    "        df['y_div_{}'.format(i)] = df['y_diff_{}'.format(i)]/(df['y_diff_inv_{}'.format(i)] + eps)\n",
    "    \n",
    "    \n",
    "    # for i in range(1, num):\n",
    "    #     df = df[df['x_lag_{}'.format(i)].notna()]\n",
    "    #     df = df[df['x_lag_inv_{}'.format(i)].notna()]\n",
    "        \n",
    "        \n",
    "    colnames_x = ['x_diff_{}'.format(i) for i in range(1, num)] + \\\n",
    "                    ['x_diff_inv_{}'.format(i) for i in range(1, num)] + \\\n",
    "                    ['x_div_{}'.format(i) for i in range(1, num)]\n",
    "    colnames_y = ['y_diff_{}'.format(i) for i in range(1, num)] + \\\n",
    "                    ['y_diff_inv_{}'.format(i) for i in range(1, num)] + \\\n",
    "                    ['y_div_{}'.format(i) for i in range(1, num)]\n",
    "    colnames = colnames_x + colnames_y\n",
    "\n",
    "    features = df[colnames]\n",
    "\n",
    "    \n",
    "    \n",
    "        \n",
    "    return preprocess_df.join(features)\n",
    "\n",
    "\n",
    "\n",
    "def prepare_data(folder_path=DATA_FOLDER):\n",
    "\n",
    "\n",
    "    frames_list = []\n",
    "\n",
    "    print(f\"Acessing data from {folder_path}\")\n",
    "\n",
    "    # 2. Loop through every file in the folder\n",
    "    for filename in tqdm(os.listdir(folder_path)):\n",
    "\n",
    "        filepath = os.path.join(folder_path, filename)\n",
    "        df_temp = pd.read_json(filepath)\n",
    "        df_temp=df_temp.T\n",
    "        \n",
    "        df_temp=preprocessing_per_file(df_temp,num=5)\n",
    "        \n",
    "        frames_list.append(df_temp)\n",
    "        \n",
    "\n",
    "\n",
    "    # Concatenate all files into one distinct DataFrame\n",
    "    full_df = pd.concat(frames_list)\n",
    "    print(full_df.isna().sum())\n",
    "\n",
    "    print(f\"Successfully created 'full_df' with shape: {full_df.shape}\")\n",
    "    return full_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df4bbc62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acessing data from ./data/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:30<00:00, 10.36it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# here we assume that all our test data would have a visible \"True\"\n",
    "# meaning x and y values are there not nan\n",
    "ASSUMPTION=False #can be changes if decides else our model would just get avg. for the nan values\n",
    "\n",
    "\n",
    "frames_list = []\n",
    "frames_original=[]\n",
    "\n",
    "print(f\"Acessing data from {DATA_FOLDER}\")\n",
    "\n",
    "# 2. Loop through every file in the folder\n",
    "for filename in tqdm(os.listdir('../data')):\n",
    "\n",
    "    filepath = os.path.join('../data', filename)\n",
    "    df_temp = pd.read_json(filepath)\n",
    "    df_temp=df_temp.T\n",
    "    if not ASSUMPTION:\n",
    "        df_temp['x'] = df_temp['x'].ffill().bfill()\n",
    "        df_temp['y'] = df_temp['y'].ffill().bfill() #better then avg\n",
    "        df_temp['visible'] = True\n",
    "    \n",
    "    \n",
    "    frames_original.append(df_temp.copy())\n",
    "    \n",
    "    df_temp=preprocessing_per_file(df_temp,num=5)\n",
    "    \n",
    "    frames_list.append(df_temp)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8fed2bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>visible</th>\n",
       "      <th>action</th>\n",
       "      <th>vx</th>\n",
       "      <th>vy</th>\n",
       "      <th>speed</th>\n",
       "      <th>ax</th>\n",
       "      <th>ay</th>\n",
       "      <th>acc_mag</th>\n",
       "      <th>jerk_mag</th>\n",
       "      <th>turn_angle_deg</th>\n",
       "      <th>...</th>\n",
       "      <th>y_diff_3</th>\n",
       "      <th>y_diff_4</th>\n",
       "      <th>y_diff_inv_1</th>\n",
       "      <th>y_diff_inv_2</th>\n",
       "      <th>y_diff_inv_3</th>\n",
       "      <th>y_diff_inv_4</th>\n",
       "      <th>y_div_1</th>\n",
       "      <th>y_div_2</th>\n",
       "      <th>y_div_3</th>\n",
       "      <th>y_div_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>324564</th>\n",
       "      <td>True</td>\n",
       "      <td>air</td>\n",
       "      <td>1.642857e+01</td>\n",
       "      <td>-2.321429e+02</td>\n",
       "      <td>2.327234e+02</td>\n",
       "      <td>-5.357143e+01</td>\n",
       "      <td>2.357143e+02</td>\n",
       "      <td>2.417253e+02</td>\n",
       "      <td>3.625880e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324565</th>\n",
       "      <td>True</td>\n",
       "      <td>air</td>\n",
       "      <td>1.464286e+01</td>\n",
       "      <td>-2.242857e+02</td>\n",
       "      <td>2.247632e+02</td>\n",
       "      <td>-8.035714e+01</td>\n",
       "      <td>3.535714e+02</td>\n",
       "      <td>3.625880e+02</td>\n",
       "      <td>1.584957e+03</td>\n",
       "      <td>0.312774</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324566</th>\n",
       "      <td>True</td>\n",
       "      <td>air</td>\n",
       "      <td>1.107143e+01</td>\n",
       "      <td>-2.085714e+02</td>\n",
       "      <td>2.088651e+02</td>\n",
       "      <td>-1.178571e+02</td>\n",
       "      <td>3.267857e+02</td>\n",
       "      <td>3.473891e+02</td>\n",
       "      <td>2.688383e+03</td>\n",
       "      <td>0.696857</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>-1.142857</td>\n",
       "      <td>-1.076923</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324567</th>\n",
       "      <td>True</td>\n",
       "      <td>air</td>\n",
       "      <td>6.785714e+00</td>\n",
       "      <td>-2.025000e+02</td>\n",
       "      <td>2.026137e+02</td>\n",
       "      <td>-1.339286e+02</td>\n",
       "      <td>5.250000e+02</td>\n",
       "      <td>5.418135e+02</td>\n",
       "      <td>1.079658e+04</td>\n",
       "      <td>1.119316</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>-1.166667</td>\n",
       "      <td>-1.153846</td>\n",
       "      <td>-1.3125</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324568</th>\n",
       "      <td>True</td>\n",
       "      <td>air</td>\n",
       "      <td>2.142857e+00</td>\n",
       "      <td>-1.735714e+02</td>\n",
       "      <td>1.735847e+02</td>\n",
       "      <td>4.821429e+01</td>\n",
       "      <td>1.066071e+03</td>\n",
       "      <td>1.067161e+03</td>\n",
       "      <td>2.740934e+03</td>\n",
       "      <td>1.211956</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>-0.857143</td>\n",
       "      <td>-1.300000</td>\n",
       "      <td>-1.7500</td>\n",
       "      <td>-1.421053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325244</th>\n",
       "      <td>True</td>\n",
       "      <td>air</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-5.115908e-11</td>\n",
       "      <td>-1.023182e-10</td>\n",
       "      <td>1.143952e-10</td>\n",
       "      <td>1.085248e-09</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325245</th>\n",
       "      <td>True</td>\n",
       "      <td>air</td>\n",
       "      <td>-3.410605e-12</td>\n",
       "      <td>-6.821210e-12</td>\n",
       "      <td>7.626345e-12</td>\n",
       "      <td>-5.115908e-11</td>\n",
       "      <td>-5.115908e-11</td>\n",
       "      <td>7.234986e-11</td>\n",
       "      <td>6.821541e-10</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325246</th>\n",
       "      <td>True</td>\n",
       "      <td>air</td>\n",
       "      <td>-3.410605e-12</td>\n",
       "      <td>-3.410605e-12</td>\n",
       "      <td>4.823324e-12</td>\n",
       "      <td>4.476419e-11</td>\n",
       "      <td>1.534772e-10</td>\n",
       "      <td>1.598721e-10</td>\n",
       "      <td>-1.260152e-10</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325247</th>\n",
       "      <td>True</td>\n",
       "      <td>air</td>\n",
       "      <td>-4.263256e-13</td>\n",
       "      <td>3.410605e-12</td>\n",
       "      <td>3.437147e-12</td>\n",
       "      <td>3.836931e-11</td>\n",
       "      <td>5.115908e-11</td>\n",
       "      <td>6.394885e-11</td>\n",
       "      <td>-8.513655e-10</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325248</th>\n",
       "      <td>True</td>\n",
       "      <td>air</td>\n",
       "      <td>-8.526513e-13</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.526513e-13</td>\n",
       "      <td>-1.278977e-11</td>\n",
       "      <td>-1.023182e-10</td>\n",
       "      <td>1.031144e-10</td>\n",
       "      <td>1.174967e-09</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>685 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        visible action            vx            vy         speed  \\\n",
       "324564     True    air  1.642857e+01 -2.321429e+02  2.327234e+02   \n",
       "324565     True    air  1.464286e+01 -2.242857e+02  2.247632e+02   \n",
       "324566     True    air  1.107143e+01 -2.085714e+02  2.088651e+02   \n",
       "324567     True    air  6.785714e+00 -2.025000e+02  2.026137e+02   \n",
       "324568     True    air  2.142857e+00 -1.735714e+02  1.735847e+02   \n",
       "...         ...    ...           ...           ...           ...   \n",
       "325244     True    air  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "325245     True    air -3.410605e-12 -6.821210e-12  7.626345e-12   \n",
       "325246     True    air -3.410605e-12 -3.410605e-12  4.823324e-12   \n",
       "325247     True    air -4.263256e-13  3.410605e-12  3.437147e-12   \n",
       "325248     True    air -8.526513e-13  0.000000e+00  8.526513e-13   \n",
       "\n",
       "                  ax            ay       acc_mag      jerk_mag  \\\n",
       "324564 -5.357143e+01  2.357143e+02  2.417253e+02  3.625880e+03   \n",
       "324565 -8.035714e+01  3.535714e+02  3.625880e+02  1.584957e+03   \n",
       "324566 -1.178571e+02  3.267857e+02  3.473891e+02  2.688383e+03   \n",
       "324567 -1.339286e+02  5.250000e+02  5.418135e+02  1.079658e+04   \n",
       "324568  4.821429e+01  1.066071e+03  1.067161e+03  2.740934e+03   \n",
       "...              ...           ...           ...           ...   \n",
       "325244 -5.115908e-11 -1.023182e-10  1.143952e-10  1.085248e-09   \n",
       "325245 -5.115908e-11 -5.115908e-11  7.234986e-11  6.821541e-10   \n",
       "325246  4.476419e-11  1.534772e-10  1.598721e-10 -1.260152e-10   \n",
       "325247  3.836931e-11  5.115908e-11  6.394885e-11 -8.513655e-10   \n",
       "325248 -1.278977e-11 -1.023182e-10  1.031144e-10  1.174967e-09   \n",
       "\n",
       "        turn_angle_deg  ...  y_diff_3  y_diff_4  y_diff_inv_1  y_diff_inv_2  \\\n",
       "324564        0.000000  ...       NaN       NaN          -6.0         -14.0   \n",
       "324565        0.312774  ...       NaN       NaN          -8.0         -15.0   \n",
       "324566        0.696857  ...       NaN       NaN          -7.0         -13.0   \n",
       "324567        1.119316  ...      21.0       NaN          -6.0         -13.0   \n",
       "324568        1.211956  ...      21.0      27.0          -7.0         -10.0   \n",
       "...                ...  ...       ...       ...           ...           ...   \n",
       "325244       90.000000  ...       0.0       0.0           0.0           0.0   \n",
       "325245       90.000000  ...       0.0       0.0           0.0           0.0   \n",
       "325246       90.000000  ...       0.0       0.0           0.0           0.0   \n",
       "325247       90.000000  ...       0.0       0.0           0.0           NaN   \n",
       "325248       90.000000  ...       0.0       0.0           NaN           NaN   \n",
       "\n",
       "        y_diff_inv_3  y_diff_inv_4   y_div_1   y_div_2  y_div_3   y_div_4  \n",
       "324564         -21.0         -27.0       NaN       NaN      NaN       NaN  \n",
       "324565         -21.0         -28.0 -0.750000       NaN      NaN       NaN  \n",
       "324566         -20.0         -23.0 -1.142857 -1.076923      NaN       NaN  \n",
       "324567         -16.0         -18.0 -1.166667 -1.153846  -1.3125       NaN  \n",
       "324568         -12.0         -19.0 -0.857143 -1.300000  -1.7500 -1.421053  \n",
       "...              ...           ...       ...       ...      ...       ...  \n",
       "325244           0.0           0.0  0.000000  0.000000   0.0000  0.000000  \n",
       "325245           0.0           NaN  0.000000  0.000000   0.0000       NaN  \n",
       "325246           NaN           NaN  0.000000  0.000000      NaN       NaN  \n",
       "325247           NaN           NaN  0.000000       NaN      NaN       NaN  \n",
       "325248           NaN           NaN       NaN       NaN      NaN       NaN  \n",
       "\n",
       "[685 rows x 37 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b6366d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>visible</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>324564</th>\n",
       "      <td>849.0</td>\n",
       "      <td>257.0</td>\n",
       "      <td>True</td>\n",
       "      <td>air</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324565</th>\n",
       "      <td>850.0</td>\n",
       "      <td>251.0</td>\n",
       "      <td>True</td>\n",
       "      <td>air</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324566</th>\n",
       "      <td>849.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>True</td>\n",
       "      <td>air</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324567</th>\n",
       "      <td>850.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>True</td>\n",
       "      <td>air</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324568</th>\n",
       "      <td>851.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>True</td>\n",
       "      <td>air</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325244</th>\n",
       "      <td>192.0</td>\n",
       "      <td>1061.0</td>\n",
       "      <td>True</td>\n",
       "      <td>air</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325245</th>\n",
       "      <td>192.0</td>\n",
       "      <td>1061.0</td>\n",
       "      <td>True</td>\n",
       "      <td>air</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325246</th>\n",
       "      <td>192.0</td>\n",
       "      <td>1061.0</td>\n",
       "      <td>True</td>\n",
       "      <td>air</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325247</th>\n",
       "      <td>192.0</td>\n",
       "      <td>1061.0</td>\n",
       "      <td>True</td>\n",
       "      <td>air</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325248</th>\n",
       "      <td>192.0</td>\n",
       "      <td>1061.0</td>\n",
       "      <td>True</td>\n",
       "      <td>air</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>685 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            x       y  visible action\n",
       "324564  849.0   257.0     True    air\n",
       "324565  850.0   251.0     True    air\n",
       "324566  849.0   243.0     True    air\n",
       "324567  850.0   236.0     True    air\n",
       "324568  851.0   230.0     True    air\n",
       "...       ...     ...      ...    ...\n",
       "325244  192.0  1061.0     True    air\n",
       "325245  192.0  1061.0     True    air\n",
       "325246  192.0  1061.0     True    air\n",
       "325247  192.0  1061.0     True    air\n",
       "325248  192.0  1061.0     True    air\n",
       "\n",
       "[685 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames_original[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ebb346",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Concatenate all files into one distinct DataFrame\n",
    "print(len(frames_list))\n",
    "print(len(frames_original))\n",
    "full_df = pd.concat(frames_list)\n",
    "original_df=pd.concat(frames_original)\n",
    "\n",
    "print(f\"Successfully created 'full_df' with shape: {full_df.shape}\")\n",
    "print(f\"original df  shape: {original_df.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9f06c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df,original_df=prepare_data_test()\n",
    "\n",
    "#full_df.to_csv('full_data_preprocessed.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
